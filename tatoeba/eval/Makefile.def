# -*-makefile-*-


## set the home directory of the repository
## this is to find the included makefiles
## (important to have a trailing '/')


SHELL    := bash
PWD      := ${shell pwd}
TODAY    := $(shell date +%F)
REPOHOME := ${PWD}/../../

include ${REPOHOME}lib/env.mk
include ${REPOHOME}lib/config.mk
include ${REPOHOME}lib/slurm.mk

GPUJOB_HPC_MEM = 20g


METRICS           := bleu spbleu chrf chrf++ comet

MODEL_STORAGE     := https://object.pouta.csc.fi/Tatoeba-MT-models
ifndef MODEL_DISTS
ifneq ($(wildcard models.missing),)
  MODEL_DISTS     := $(shell cat models.missing)
else
  MODEL_DISTS     := ${shell ${WGET} -q -O - ${MODEL_STORAGE}/index.txt | grep '.zip$$' | grep -v '.eval.zip$$'}
endif
endif

MODEL_DIST         = ${firstword ${MODEL_DISTS}}
MODEL              = ${MODEL_DIST:.zip=}
MODEL_LANGPAIR     = ${firstword ${subst /, ,${MODEL_DIST}}}
MODEL_URL          = ${MODEL_STORAGE}/${MODEL_DIST}
MODEL_EVAL_URL     = ${MODEL_URL:.zip=.eval.zip}

## directory with all test sets (submodule OPUS-MT-testsets)
TESTSET_HOME   := ${REPOHOME}OPUS-MT-testsets/testsets
TESTSET_INDEX  := ${REPOHOME}OPUS-MT-testsets/index.txt

## work directory (for the temporary models)
WORK_HOME      = ${PWD}
WORK_DIR       = ${WORK_HOME}/${MODEL}

## model directory (for test results)
## model score file and zipfile with evaluation results
# MODEL_HOME     = ${REPOHOME}models-tatoeba
MODEL_HOME      = ${REPOHOME}tatoeba/models
MODEL_DIR       = ${MODEL_HOME}/${MODEL}
MODEL_SCORES    = ${MODEL_DIR}.scores.txt
MODEL_EVALZIP   = ${MODEL_DIR}.eval.zip
LEADERBOARD_DIR = ${REPOHOME}scores

MODEL_BLEUSCORES    = ${MODEL_DIR}.bleu-scores.txt
MODEL_CHRFSCORES    = ${MODEL_DIR}.chrf-scores.txt
MODEL_COMETSCORES   = ${MODEL_DIR}.comet-scores.txt

## all zip files with benchmark results
MODEL_EVALZIPS := ${patsubst %.zip,${MODEL_HOME}/%.eval.zip,${MODEL_DISTS}}


## collected scores for a model using a specific metric
MODEL_METRIC_SCORES = $(patsubst %,${MODEL_DIR}.%-scores.txt,${METRICS})
